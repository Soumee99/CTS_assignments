{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 #importing open cv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  cv2.imread () method loads an image from the specified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_c=cv2.imread(\"C:\\\\Users\\\\2211444\\\\Downloads\\\\Trudeau.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the color image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_g=cv2.cvtColor(image_c,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **.imshow** :cv2.imshow() method is used to display an image in a window. \n",
    "\n",
    "**cv2 waikey ()** : waits for the pressed key event before going to the next set of operations. Its syntax is as follows – Syntax cv2.waitKey (delay) It waits for ‘delay’ milliseconds for any positive value of ‘delay’. And for any negative value of ‘delay’ or when ‘delay’ = 0, the function waits infinitely for a key event.\n",
    "**cv2.destroyAllWindows()**:. destroyWindow () only destroys a specific window but in the case of destroyAllWindow () it destroys all windows.\n",
    "\n",
    "\n",
    "#### Displaying the image in color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Trudeau in Color',image_c) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the image in greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Trudeau in Grey',image_g)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. (reference: https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html)\n",
    "\n",
    "\n",
    "OpenCV provides a training method (see Cascade Classifier Training) or pretrained models, that can be read using the cv::CascadeClassifier::load method.\n",
    "a cv::CascadeClassifier is created and the necessary XML file is loaded using the cv::CascadeClassifier::load method. Afterwards, the detection is done using the **cv::CascadeClassifier::detectMultiScale** method, which returns boundary rectangles for the detected faces or eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters .detectMultiScake takes are  read_img, scale factor , minNeihbours \n",
    "\n",
    "\n",
    "**read_img**: Image to be read\n",
    "**scaleFactor**:  it specifies how much the image size is reduced with each scale.\n",
    "**MinNeighbours**: specifies how many neighbors each candidate rectangle should have to retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=face_detection.detectMultiScale(image_c,1.1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.shape #checking the shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If faces are found, it returns the positions of detected faces as Rect(x,y,w,h). Once we get these locations, we can create a ROI for the face and apply eye detection on this ROI (since eyes are always on the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[332, 121, 208, 208]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces #this is the coordinate for the area where it found the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x,y are pixel location of faces, w,h are width and height of faces. \n",
    "**cv2.rectangle()** function used for draw rectangle over the detected object, image_c is input image, (x,y),(x+w, y+h) are locations of rectangle,(0,255,255) is color of a rectangle this argument gets passed as a tuple for BGR,we would use (0,0,255) for red, 3 is thickness of rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=int(faces[:,0])\n",
    "y=int(faces[:,1])\n",
    "w=int(faces[:,2])\n",
    "h=int(faces[:,3])\n",
    "\n",
    "cv2.rectangle(image_c,(x,y),(x+w,y+h),(0,255,255),3)\n",
    "cv2.imshow(\"Single  Face Detection\",image_c)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Multiple faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_c=cv2.imread(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\Scientist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_g=cv2.cvtColor(image_c,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Scientist in Color',image_c)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Scientist in greyscale',image_g)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_frontalface_default.xml\")\n",
    "faces=face_detection.detectMultiScale(image_c,1.1,5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image_c,(x,y),(x+w,y+h),(255,0,255),10)\n",
    "    cv2.imshow('Single face Detection',image_c)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect eyes and faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_c=cv2.imread(\"C:\\\\Users\\\\2211444\\\\Downloads\\\\Trudeau.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_frontalface_default.xml\")\n",
    "eye_classifier=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_classifier.detectMultiScale(image_c, 1.2, 5)\n",
    " \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image_c,(x,y),(x+w,y+h),(0,255,255), 3)\n",
    "    cv2.imshow('Trudeau Face and Eyes',image_c)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Select the face\n",
    "    face_region = image_c[y:y+h, x:x+w]\n",
    "\n",
    "    eyes = eye_classifier.detectMultiScale(face_region)\n",
    "\n",
    "    for (eyes_x, eyes_y, eyes_w,eyes_h) in eyes:\n",
    "        cv2.rectangle(face_region,(eyes_x, eyes_y),(eyes_x + eyes_w, eyes_y + eyes_h), (0,255,0),3)\n",
    "        cv2.imshow('Trudeau Face and Eyes',image_c)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Face Region',image_c[y:y+h,x:x+w])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
