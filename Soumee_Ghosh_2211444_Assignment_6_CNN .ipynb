{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ3eUwdQ37a4"
   },
   "source": [
    "# CNN\n",
    "The first thing we need to know is the elements that are included in the CNN operation:\n",
    "\n",
    "\n",
    "\n",
    "*   Input image\n",
    "*   Convolutional Neural Network\n",
    "\n",
    "\n",
    "*   Output label (image class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9_eoJJ24xjW"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8e-mdtkoQhvB"
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #viusalization library\n",
    "import random # used to generate  random numbers\n",
    "\n",
    "from keras.datasets import mnist #importing the dataset\n",
    "from keras.models import Sequential #Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Activation # importing the core layers \n",
    "from keras.utils import np_utils #from the utils module importing numpy utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvmCX2j15BVd"
   },
   "source": [
    "**Random** - Python Random module is an in-built module of Python which is used to generate random. \n",
    "\n",
    "**Keras** : Keras is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.\n",
    "\n",
    "From the keras library we call upon the datasets class and from there we import mnist dataset.\n",
    "From the keras models module we import sequential class. \n",
    "The Sequential model, which is very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers.\n",
    "\n",
    "**Layers**: Layers are the basic building blocks of neural networks in Keras.\n",
    "\n",
    "From layers api we import te dense, activatin and dropout classes from the core layers module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdReq_Jw-NY8"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adx8xMMY-W7C"
   },
   "source": [
    "Importing Preorocessing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PdAlxCCwREkY"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator #from keras image data preprocessing library importing imageDataGenerator to generate images\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D,GlobalAveragePooling2D,Flatten \n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1loUnEcd-_5W"
   },
   "source": [
    "**Conv2D**: We find this under the layers module .2D convolution layer (e.g. spatial convolution over images).\n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of output.\n",
    "\n",
    "**MaxPooling2D**: this is used during the max pooling step.\n",
    "\n",
    "**ZeroPadding2D**: this layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.\n",
    "\n",
    "**Flatten & Global Average Pooling**\n",
    "\n",
    "**Flatten** will take a tensor of any shape and transform it into a one dimensional tensor (plus the samples dimension) but keeping all values in the tensor. For example a tensor (samples, 10, 20, 1) will be flattened to (samples, 10 * 20 * 1). it converts to 1D array that is then fed to the ANN\n",
    "\n",
    "**GlobalAveragePooling2D** does something different. This function is used to operate global average pooling for given data.\n",
    "For example, suppose we have an input feature map of dimensions height(h), width, and depth. When we pass this input layer into the global average pooling operation then it will calculate the average value of every single map and returns the average value to the output node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymTn7YoKB67n"
   },
   "source": [
    " **Batch Normalization** :Layer that normalizes its inputs.\n",
    "\n",
    "Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFR7b57OCHnb"
   },
   "source": [
    "## Loading the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73GL267HCPhr"
   },
   "source": [
    "Splitting into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocecqibMS_uY",
    "outputId": "669730dc-07aa-4803-8bce-ef805ba80d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "X_train_shape (60000, 28, 28)\n",
      "X_test_shape (10000, 28, 28)\n",
      "y_train_shape (60000,)\n",
      "y_test_shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=mnist.load_data() #splitting into training and test set\n",
    "\n",
    "#Checking the shape of the data.\n",
    "print(\"X_train_shape\", X_train.shape)\n",
    "print(\"X_test_shape\", X_test.shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"y_test_shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJO6X5-9Cdaq"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uD-TY-EAUltH"
   },
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(60000,28,28,1) #reshaping the data, adding 1 to specify that our image is a black and white image \n",
    "X_test=X_test.reshape(10000,28,28,1)\n",
    "\n",
    "X_train=X_train.astype('float32') #converting the data into a float type\n",
    "X_test=X_test.astype('float32')\n",
    "\n",
    "X_train /=255 # since each pixel takes a valiue between 0 and 255 so dividing by 255 we are features scaling\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi16CHtsDkS7"
   },
   "source": [
    "## Encoding the catgorical columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KnI0lG1zUzPZ"
   },
   "outputs": [],
   "source": [
    "nb_classes=10 #we have 10 classes in our data\n",
    "\n",
    "Y_train=np_utils.to_categorical(y_train,nb_classes)  # to_categorical class: Converts a class vector (integers) to binary class matrix.\n",
    "Y_test=np_utils.to_categorical(y_test,nb_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtr8r8QWELFj"
   },
   "source": [
    "# Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEpVdKgNESdF"
   },
   "source": [
    "## Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2Fg4kpilU6A6"
   },
   "outputs": [],
   "source": [
    "model= Sequential() #buiding an instance model which is a sequence of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NscjDoMnEias"
   },
   "source": [
    "## Step 1: Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvnbj9hSEqNe"
   },
   "source": [
    "Adding the first convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i_TgtMY1U9YY"
   },
   "outputs": [],
   "source": [
    "#Convolution Layer 1\n",
    "model.add(Conv2D(32,(3,3),input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNxwC2KUEvdq"
   },
   "source": [
    "**add method** is called on model object to add our very first layer which will be an object of Conv2D class.\n",
    "from the keras library we call layers module from where we call the Conv2D class\n",
    "the filters parameter is for how many feature detectors we want and the kernel size specifies the no of rows and columns of the feature map(3x3)\n",
    "so  32 is the no of feature detectors and the size of those are 3x3.\n",
    "\n",
    "**input_shape**: the input_shape specifies the shape.Since here we are working with black-white images and we resized our images earlier to (28,28)\n",
    " so we specify the input_shape as (28,28,1) where 1 specifies that its a black & white image  . For colored we write 3 instead of 1  because of RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FwMvbfjSyO5"
   },
   "source": [
    "Normalizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K-ry_cpXVTT8"
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLELK1JZSH-X"
   },
   "source": [
    "It is the layer that normalizes its inputs.\n",
    "Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsDotHaiTDm1"
   },
   "source": [
    "## Adding the  activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "85FIsr7oVZ9r"
   },
   "outputs": [],
   "source": [
    "convLayer01 = Activation('relu')  #adding the rectifier activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_5TWz2pTzql"
   },
   "source": [
    "Activations can either be used through an Activation layer, or through the activation argument supported by all forward layers.\n",
    "**relu**:Applies the rectified linear unit activation function.\n",
    "\n",
    "With default values, this returns the standard ReLU activation: max(x, 0), the element-wise maximum of 0 and the input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25gVGnnZUhvt"
   },
   "source": [
    "## Adding the 2nd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TNJqJZ0FVg6u"
   },
   "outputs": [],
   "source": [
    "#ConvolutionLayer2\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-QZlWVmVf5m"
   },
   "source": [
    "**NOTE** :  here we dont need the input_shape parameter as when add the first layer we already connected it to the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dfDe8rYJVvWs"
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization(axis=-1)) #we follow similar batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9T5lCGG3WiyC"
   },
   "source": [
    "**Note**: we might have confusion regarding axis=-1\n",
    "\n",
    "When we compute a BatchNormalization along an axis, we preserve the dimensions of the array, and we normalize with respect to the mean and standard deviation over every other axis. So in your 2D example BatchNormalization with axis=1 is subtracting the mean for axis=0, just as you expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEK0lQ11XCpe"
   },
   "source": [
    "## STEP 2: MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mAf8Ob_GVzs3"
   },
   "outputs": [],
   "source": [
    "convLayer02=MaxPooling2D(pool_size=(2,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxRUrqaTXRIy"
   },
   "source": [
    " layers module having the MaxPool2d class\n",
    " \n",
    " **pool_size**=2 i.e. we apply a 2x2 max pool filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq4BUZIkXbk3"
   },
   "source": [
    "Adding the max pooling layer to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LEz4LSZOV8Vp"
   },
   "outputs": [],
   "source": [
    "model.add(convLayer02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cbO66GyXgpi"
   },
   "source": [
    "Adding third convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1M8Vi7D0WDyj"
   },
   "outputs": [],
   "source": [
    "#convolutionLayer3\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "convLayer03=Activation('relu')\n",
    "model.add(convLayer03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfV8qi9OYDSW"
   },
   "source": [
    "Adding the Fourth convolution layer and then adding a max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Us4ss2qLWhze"
   },
   "outputs": [],
   "source": [
    "#convolutionLayer4\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "convLayer03=Activation('relu')\n",
    "convLayer04=MaxPooling2D(pool_size=(2,2))\n",
    "model.add(convLayer04)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIj32Rv5YT9Y"
   },
   "source": [
    "## Step 3:  Flattening\n",
    "\n",
    "\n",
    "converting the convolutional layer and pooling layer into a one dimensional vector that we will feed to our ANN\n",
    "from keras library we call the layers module and the flatten class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eT2991RqYURk"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXxu8jAEYh3v"
   },
   "source": [
    "## Step 4: Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "B6Cg_A_AW7Rm"
   },
   "outputs": [],
   "source": [
    "#Fully Connected Layer 5\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0BKfkCQYrsr"
   },
   "source": [
    " **Dense** is used to add a fully connected to our model.\n",
    " we call the dense class which takes parameters units.\n",
    "units is the no of hidden layers you want to have, with high no of neurons we get better accuracy. Here we take 512 neurons.\n",
    "we perform batch normalization and then add a rectifier activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAvIoenIZD5V"
   },
   "source": [
    "Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1tKMVXCQXPn3"
   },
   "outputs": [],
   "source": [
    "#Fully Connected layer 6\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPrnc5ANZSkz"
   },
   "source": [
    "Here we add the number of units=10 as we have 10 classes in our data.\n",
    "pplies Dropout to the input.\n",
    "\n",
    "The **Dropout layer** randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
    "\n",
    "**softmax activation function**: Softmax converts a vector of values to a probability distribution.The elements of the output vector are in range (0, 1) and sum to 1. Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpVscHk6aMPu"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEuPmsceXuJm",
    "outputId": "41d96d03-4487-4c25-f0b3-4dff3de508d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 10, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 597,738\n",
      "Trainable params: 596,330\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7Z0hWHzaPnt"
   },
   "source": [
    "We get the total trainable parameters as 596,330\n",
    "non trainable parameters as 1408\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In neural networks in general, and in deep learning algorithms (CNN, DNN, etc.) that are also based on neural networks, trainable parameters are parameters that will be learned by the model during the training procedure such as weights and biases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWkLMYcVbLoT"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js6-sXIqbFHv"
   },
   "source": [
    "## Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKPR90nZmwMX"
   },
   "source": [
    "**.compile** : configures the model for training.\n",
    "\n",
    "**Adam**: Optimizer that implements the Adam algorithm.Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.Adam,the optimizer updates the weight.\n",
    "\n",
    "**loss**: The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n",
    "\n",
    "**Note**:For binary prediction the loss function is binary_crossentropy and here since we have more than 2 classes i.e. 10 classes our loss function is \n",
    "\n",
    "**Categorical crossentropy**: Computes the crossentropy loss between the labels and predictions.We use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a one_hot representation.\n",
    "\n",
    "**Accuracy** : the metrics for evaluation. The accuracy class calculates how often predictions equal labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "McxxfJybXwGc"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGmzuBzMpT6k"
   },
   "source": [
    " We are applying transformations in the images to avoid overfitting i.e. image augmentation.\n",
    "\n",
    "test_gen is an instance of ImagedataGenerator class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pipkSoA9YE9w"
   },
   "outputs": [],
   "source": [
    "# data augmentation prevents overfitting by slightly changing the data randomly\n",
    "# Keras has a great built-in feature to do automatic augmentation\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08,\n",
    "                         shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF_OYzSZrGuw"
   },
   "source": [
    "In Keras via the keras.preprocessing.image.ImageDataGenerator class we can:\n",
    "\n",
    "\n",
    "*   configure random transformations and normalization operations to be done on your image data during training\n",
    "\n",
    "*   instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator.\n",
    "\n",
    "**rotation_range** is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "\n",
    "**width_shift** and **height_shift** are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
    "\n",
    "**shear_range** is for randomly applying shearing transformations\n",
    "**zoom_range** is for randomly zooming inside pictures\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VPP9RDvsIVE"
   },
   "source": [
    "We can feed our augumented data in batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xqnbAjiiYLAn"
   },
   "outputs": [],
   "source": [
    "train_generator= gen.flow(X_train,Y_train,batch_size=128)\n",
    "test_generator= test_gen.flow(X_test,Y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zXUjOM_uja6"
   },
   "source": [
    "## Fitting our model\n",
    "\n",
    ".fit method on ann object to train our model\n",
    "batch training is more efficient in artificial training since training in batches is efficient.\n",
    "\n",
    "\n",
    "We call fit(), which will train the model by slicing the data into \"batches\" of size batch_size, and repeatedly iterating over the entire dataset for a given number of epochs.\n",
    "\n",
    "defualt value of batch training =32, we have taken 128\n",
    "steps per epoch= total training data divided by no of batches.\n",
    "\n",
    "epochs =5 i.e. we will train the data in batches and will repeatedly iterate over the entire dataset 5 times.\n",
    "\n",
    "verbose=1. Verbosity mode 1 shows  progress bar\n",
    "\n",
    "validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. We will evaluate on test data.\n",
    "\n",
    "validation_steps: validation of training data is also done in batches ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QppYIREbY2It",
    "outputId": "3fb7d9e3-e83e-41b9-ada7-d3a44ac6c609"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "468/468 [==============================] - 181s 384ms/step - loss: 0.1547 - accuracy: 0.9521 - val_loss: 0.0687 - val_accuracy: 0.9806\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 174s 371ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.0375 - val_accuracy: 0.9886\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 174s 372ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.0422 - val_accuracy: 0.9853\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 181s 388ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0234 - val_accuracy: 0.9921\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 175s 373ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.0463 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19b3ba9f50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,steps_per_epoch=60000//128,epochs=5,verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=10000//128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X1kXqMvwU1C"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Returns the loss value & metrics values for the model in test mode.\n",
    "Test score and test accuracy are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwp1Q1OgbUp7",
    "outputId": "449dee08-e259-4128-f751-3813e42f5d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0463 - accuracy: 0.9840\n",
      "Test score: 0.04625951871275902\n",
      "Test accuracy: 0.984000027179718\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64fU02ms7Ef3"
   },
   "source": [
    "The test loss is 0.0325 and the accuracy of our model is 98.9 %.\n",
    "The test score is 3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPR8MiYGCNyc"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rXTdU2ejXPx",
    "outputId": "44ceb786-765a-4433-ec50-83cf64e0c65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 22ms/step\n",
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test) \n",
    "Y_pred = np.argmax(Y_pred, axis = -1)[:5] #predicting the output array of the first five images\n",
    "Y_true = np.argmax(Y_test,axis = -1)[:5]  #true output of first five images\n",
    "\n",
    "#we compare the true value with predicted value\n",
    "print(Y_pred) \n",
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgpiLxIfCKYu"
   },
   "source": [
    "The output of both array is identical and it indicate our model correctly predicts the first five images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7GQhsLtBNDQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
